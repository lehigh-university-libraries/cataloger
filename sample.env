# LLM Provider Configuration
# Supported providers: openai, azure, gemini, ollama
CATALOGING_PROVIDER=ollama

# OpenAI Configuration
OPENAI_API_KEY=sk-proj-your-openai-api-key-here
OPENAI_MODEL=gpt-4o

# Azure OpenAI Configuration
# AZURE_API_KEY=your-azure-api-key
# AZURE_ENDPOINT=https://your-instance.openai.azure.com
# AZURE_DEPLOYMENT=your-deployment-name
# AZURE_MODEL=gpt-4o

# Google Gemini Configuration
# GEMINI_API_KEY=your-gemini-api-key
# GEMINI_MODEL=gemini-pro-vision

# Ollama Configuration (for local models)
# Use OLLAMA_URL for remote instances, or OLLAMA_HOST for local
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=mistral-small3.2:24b

# Classification Models
EMBEDDING_MODEL=qwen-0.6b
VISION_MODEL=siglip
